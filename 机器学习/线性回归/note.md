## 线性回归
- 线性回归：寻找一种能预测的趋势
- 线性关系模型
- ![线性关系模型](/Users/mac/Desktop/spider/机器学习/线性回归/线性关系模型.jpeg)
- 定义：线性回归通过一个或者多个自变量与因变量之间进行建模的回归分析。其中可以为一个或多个自变量之间的线性组合（线性回归的一种）
- 一元线性回归：涉及到的变量只有一个
- 多元线性回归：涉及到的变量两个或两个以上
- 公式：
- ![线性回归](/Users/mac/Desktop/spider/机器学习/线性回归/线性回归.jpeg)
- 矩阵：大多数算法的计算基础，必须是二维的。满足特定的运算需求
	- 矩阵乘法：（m行，l列）*（l行，n列）=（m行，n列）

### 损失函数（误差大小）
- ![损失函数](/Users/mac/Desktop/spider/机器学习/线性回归/损失函数.jpeg)

- 如何去求模型当中的W，使得损失最小？（目的是找到最小损失对应的W值）
	- 1，最小二乘法值正规方程
	- ![最小二乘法之正规方程](/Users/mac/Desktop/spider/机器学习/线性回归/最小二乘法之正规方程.jpeg)
	- 2，最小二乘法之梯度下降
	- ![最小二乘法之梯度下降](/Users/mac/Desktop/spider/机器学习/线性回归/最小二乘法之梯度下降.jpeg)
	- 梯度下降求w最小值动态示意图
	- ![IMG_0067](/Users/mac/Desktop/spider/机器学习/线性回归/IMG_0067.gif)

### sklearn线性回归正规方程、梯度下降API
- sklearn.liner_model.LinerRegression
	- 正规方程
	- 普通最小二乘线性回归
	- coef_:回归系数
	
- sklearn.liner_model.SGDRegressor
	- 梯度下降（手动指定学习率。）
	- 通过使用SGD最小化线性模型
	- coef_:回归系数

### 线性回归实例
- 1，波士顿房价数据集分析流程
	- 1，波士顿地区房价数据获取
	- 2，波士顿地区房价数据分割
	- **3，训练与测试数据标准化处理**
	- 4，使用最简单的线性回归模型LinerRegression和梯度下降估计SGDRegressor对房价进行预测

### 回归性能评估

- 均方误差
- ![均方误差](/Users/mac/Desktop/spider/机器学习/线性回归/均方误差.jpeg)
- mean_squared_error
	- mean_squared_error(y_true,y_pred)
		- 均方误差回归损失
		
		- y_true:真实值
		
		- y_pred:预测值
		
		- return:浮点数结果
		
		- 注意：真实值，预测值为标准化之前的值
	
- 梯度下降和正规方程对比
- ![梯度下降和正规方程对比](/Users/mac/Desktop/spider/机器学习/线性回归/梯度下降和正规方程对比.jpeg)
- 1，LinerRegression与SGDRegressor评估
- 2，特点：线性回归器是最为简单、易用的回归模型。从某种角度上限制了使用，尽管如此，在不知道特征之间关系的前提下，我们仍然使用线性回归器作为大多数系统的首要选择。
	- 小规模数据：LinerRegression（不能解决拟合问题）以及其它
	- 大规模数据：SGDRegressor

### 过拟合和欠拟合
- 模型复杂的原因：数据的特征和目标值之间的关系不仅仅是线性关系
- 问题：训练集数据训练的很好，误差也不大，为什么在测试集上面有问题呢？
- ![欠拟合和过拟合](/Users/mac/Desktop/spider/机器学习/线性回归/欠拟合和过拟合.jpeg)
- 过拟合：一个假设在训练集数据上能够获得比其它假设更好的拟合，但是在训练集数据外的数据集上却不能很好的拟合数据，此时认为这个假设出现了过拟合的现象（模型过于复杂）
- 欠拟合：一个假设在训练集上不能获得更好的拟合，但是在训练集数据外的数据集上页不能很好的拟合数据，此时认为这个假设出现了欠拟合的现象（模型过于简单）

- 欠拟合原因以及解决办法
	- 原因：学习到数据的特征过少
	- 解决办法：增加数据的特征数量
- 过拟合原因以及解决办法
	- 原因：原始特征过多，存在一些嘈杂的特征，模型过于复杂是因为模型尝试去兼顾各个测试数据点
	- 解决办法：
		- 进行特征选择，消除关联性大的特征（很难做到）
		- 交叉验证（让所有数据都有过训练）
		- 正则化
	- L2正则化
		- 作用：可以使得W的每个元素都很小，都接近于0
		- 优点：越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象

- 线性回归：LinerRegression 容易出现过拟合，为了把训练集数据表现更好，使用L2正则化
	- Ridge：岭回归 带有正则化的线性回顾，解决过拟合问题
	- API：sklearn.liner_model.Ridge(alpha=1.0)
		- 具有L2正则化的线性最小二乘法
		- alpha：正则化力度
		- coef_:回归系数

### sklearn模型的保存和加载
- from sklearn.externals import joblib
- 保存和加载API
	- 保存：joblib.dump(rf,'test.pkl')
	- 加载：estimator = joblib.load('test.pkl')	- 注意：文件格式pkl		

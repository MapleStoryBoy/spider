## 分类算法-朴素贝叶斯算法
- 朴素贝叶斯使用场景：特征独立
- 朴素贝叶斯公式
- ![朴素贝叶斯公式](/Users/mac/Desktop/spider/机器学习/机器学习概述/朴素贝叶斯公式.jpeg)

- 公式分为三部分：
	- P(C):每个文档类别的概率（某文档类别数/总文档数量）
	- P(W/C):给定类别下特征（被预测文档中出现的词）的概率
		- 计算方法：P(F1|C) = Ni/N  (训练文档中去计算)
			- Ni为该F1词在C类别所有文档中出现的次数
			- N为所属类别C下的文档所有词出现的次数和
	- P(F1,F2,...)  预测文档中每个词的概率

- 拉普拉斯平滑系数
	-  解决词频列表里很多出现次数为0的现象。
	-  公式：P(F1|C) = (Ni+a)/(N+am)
		- a为指定的系数一般为1，m为训练文档中统计出的特征词个数

### 联合概率和条件概率
- 联合概率：包含多个条件，且所有条件同时成立的概率
	- 记作：P(A,B): P(A,B)=P(A)P(B)

- 条件概率：就是事件A在另外一个事件B已经发生条件下的发生概率
	- 记作：P(A|B)
	- 特性：P(A1,A2|B)=P(A1|B)P(A2|B)
	- 注意：此条件概率的成立，是由于A1，A2相互独立的结果

### sklearn朴素贝叶斯实现API
- sklearn.naive_bayes.MultinomialNB
- MultinomialNB函数
	- sklearn.naive_bayes.MultinomialNB(alpha=1.0)
		- 朴素贝叶斯分类
		- alpha：拉普拉斯平滑系数

- 注意：
	- 训练集误差大的化，它的结果肯定不好。
	- 不需要调参

- 朴素贝叶斯分类的优缺点
	- 优点：
		- 朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率
		- 对缺失数据不太敏感，算法也比较简单，常用于文本分类
		- 分类准确度高，速度快
	- 缺点：
		- 由于使用了样本属性独立性的假设，所以如果样本属性有关联时其效果不好。

		
## 分类模型的评估
- estimator.score()
	- 一般最常见使用的是准确率，即预测结果正确的百分比

### 混淆矩阵
- 在分类任务下，预测结果(Predicted Condition)与正确标记(True Condition)之间存在四种不同的组合，构成混淆矩阵(适用于多分类)

- 引出评估标准
	- 准确率
	- 精确率和召回率
- 分类模型评估API
- sklearn.metrics.classification_report(y_true,y_pred,target_names=None)
	- y_true:真实的目标值
	- y_pred:估计器预测目标值
	- target_names:目标类别名称
	- return:每个类别精确率与召回率

